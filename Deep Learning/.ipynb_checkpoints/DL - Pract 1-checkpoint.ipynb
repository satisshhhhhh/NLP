{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdad3cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c073dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(x):\n",
    "    if x > 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5970d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input database\n",
    "inputs = np.array([[0,0], [0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ab6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random weights and bias initialization\n",
    "hidden_weights = np.array([[1,-1], [-1,1]])\n",
    "hidden_bias = np.array([1,1,1,1])\n",
    "output_weights = [2,2]\n",
    "output_bias = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d0ddc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hiddden weights: \n",
      "[[ 1 -1]\n",
      " [-1  1]]\n",
      "Initial hiddden bias: [1 1 1 1]\n",
      "Initial output weights: [2, 2]\n",
      "Initial output biases: [2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial hiddden weights: \")\n",
    "print(hidden_weights)\n",
    "print(f\"Initial hiddden bias: {hidden_bias}\")\n",
    "print(f\"Initial output weights: {output_weights}\")\n",
    "print(f\"Initial output biases: {output_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77be1607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input combination     :  1\n",
      "Hidden layer neuron 1 :  1\n",
      "After threshold       :  [0]\n",
      "Hidden layer neuron 2 :  1\n",
      "After threshold       :  [0]\n",
      "Input combination     :  2\n",
      "Hidden layer neuron 1 :  0\n",
      "After threshold       :  [0, 0]\n",
      "Hidden layer neuron 2 :  2\n",
      "After threshold       :  [0, 1]\n",
      "Input combination     :  3\n",
      "Hidden layer neuron 1 :  2\n",
      "After threshold       :  [0, 0, 1]\n",
      "Hidden layer neuron 2 :  0\n",
      "After threshold       :  [0, 1, 0]\n",
      "Input combination     :  4\n",
      "Hidden layer neuron 1 :  1\n",
      "After threshold       :  [0, 0, 1, 0]\n",
      "Hidden layer neuron 2 :  1\n",
      "After threshold       :  [0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_activation1 = []\n",
    "hidden_layer_activation2 = []\n",
    "for i in range(len(inputs)):\n",
    "    print(\"Input combination     : \",i+1)\n",
    "    hidden_layer1=inputs[i][0]*hidden_weights[0][0]+inputs[i][1]*hidden_weights[0][1]+1\n",
    "    print(\"Hidden layer neuron 1 : \",hidden_layer1)\n",
    "    hidden_1 = threshold(hidden_layer1)\n",
    "    hidden_layer_activation1.append(hidden_1)\n",
    "    print(\"After threshold       : \",hidden_layer_activation1)\n",
    "    hidden_layer2=inputs[i][0]*hidden_weights[1][0]+inputs[i][1]*hidden_weights[1][1]+1\n",
    "    print(\"Hidden layer neuron 2 : \",hidden_layer2)\n",
    "    hidden_2 = threshold(hidden_layer2)\n",
    "    hidden_layer_activation2.append(hidden_2)\n",
    "    print(\"After threshold       : \",hidden_layer_activation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77d456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0]\n",
      "[0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(hidden_layer_activation1)\n",
    "print(hidden_layer_activation2)\n",
    "outputs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c354f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden combination 1\n",
      "Output layer : 0\n",
      "Hidden combination 2\n",
      "Output layer : 2\n",
      "Hidden combination 3\n",
      "Output layer : 2\n",
      "Hidden combination 4\n",
      "Output layer : 0\n",
      "Output: [0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hidden_layer_activation1)):\n",
    "    print(\"Hidden combination\", i + 1)\n",
    "    output_layer = hidden_layer_activation1[i] * output_weights[0] \n",
    "    + hidden_layer_activation2[i] * output_weights[1] + output_bias\n",
    "    print(\"Output layer :\", output_layer)\n",
    "    output = threshold(output_layer)\n",
    "    outputs.append(output)\n",
    "print(\"Output:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea9bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cb06f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hidden weights:\n",
      "[[ 2 -2]\n",
      " [-2  2]]\n",
      "Initial hidden biases:\n",
      "[1 1 1 1]\n",
      "Initial output weights:\n",
      "[1 1]\n",
      "Initial output biases:\n",
      "0\n",
      "Input combination 1\n",
      "Hidden layer neuron 1: 1\n",
      "After threshold: [0]\n",
      "Hidden layer neuron 2: 1\n",
      "Input combination 2\n",
      "Hidden layer neuron 1: -1\n",
      "After threshold: [0, 0]\n",
      "Hidden layer neuron 2: 3\n",
      "Input combination 3\n",
      "Hidden layer neuron 1: 3\n",
      "After threshold: [0, 0, 1]\n",
      "Hidden layer neuron 2: -1\n",
      "Input combination 4\n",
      "Hidden layer neuron 1: 1\n",
      "After threshold: [0, 0, 1, 0]\n",
      "Hidden layer neuron 2: 1\n",
      "[0, 0, 1, 0]\n",
      "[0, 1, 0, 0]\n",
      "Hidden combination 1\n",
      "Hidden layer neuron 1: 0\n",
      "Hidden combination 2\n",
      "Hidden layer neuron 1: 1\n",
      "Hidden combination 3\n",
      "Hidden layer neuron 1: 1\n",
      "Hidden combination 4\n",
      "Hidden layer neuron 1: 0\n",
      "Output: [0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "def threshold (x):\n",
    "  if x > 1:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "def threshold_2(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Input datasets\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "expected_output = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Random weights and bias initialization\n",
    "hidden_weights = np.array([[2, -2], [-2, 2]])\n",
    "hidden_bias = np.array([1, 1, 1, 1])\n",
    "output_weights = np.array([1, 1])\n",
    "output_bias = 0\n",
    "\n",
    "print(\"Initial hidden weights:\")\n",
    "print(hidden_weights)\n",
    "print(\"Initial hidden biases:\")\n",
    "print(hidden_bias)\n",
    "print(\"Initial output weights:\")\n",
    "print(output_weights)\n",
    "print(\"Initial output biases:\")\n",
    "print(output_bias)\n",
    "hidden_layer_activation1 = []\n",
    "hidden_layer_activation2 = []\n",
    "for i in range(len(inputs)):\n",
    "    print(\"Input combination\", i + 1)\n",
    "    hidden_layer1 = inputs[i][0] * hidden_weights[0][0] + inputs[i][1] * hidden_weights[0][1] + hidden_bias[0]\n",
    "    print(\"Hidden layer neuron 1:\", hidden_layer1)\n",
    "    hidden_1 = threshold(hidden_layer1)\n",
    "    hidden_layer_activation1.append(hidden_1)\n",
    "    print(\"After threshold:\", hidden_layer_activation1)\n",
    "    hidden_layer2 = inputs[i][0] * hidden_weights[1][0] + inputs[i][1] * hidden_weights[1][1] + hidden_bias[1]\n",
    "    print(\"Hidden layer neuron 2:\", hidden_layer2)\n",
    "    hidden_2 = threshold(hidden_layer2)\n",
    "    hidden_layer_activation2.append(hidden_2)\n",
    "\n",
    "print(hidden_layer_activation1)\n",
    "print(hidden_layer_activation2)\n",
    "outputs=[]\n",
    "for i in range(len(hidden_layer_activation1)):\n",
    "    print(\"Hidden combination\", i + 1)\n",
    "    output_layer = hidden_layer_activation1[i] * output_weights[0] + hidden_layer_activation2[i] * output_weights[1] + output_bias\n",
    "    print(\"Hidden layer neuron 1:\", output_layer)\n",
    "    output = threshold_2(output_layer)\n",
    "    outputs.append(output)\n",
    "print(\"Output:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9063e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26cfff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbc4e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bf2403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b9aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e6f321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d9ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb71ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e4906d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b28611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff1d737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c5a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81804240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a304b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772fe2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183eb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e86603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c74e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161dc137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f50e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4213a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff86df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd075fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4efedca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining With Randomly Generated Weights\n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "Weights After Training : \n",
      "[[  8.44475793]\n",
      " [  8.44475793]\n",
      " [-12.75314898]]\n",
      "New Output Data : \n",
      "[0.98427056]\n",
      "Random weights init\n",
      "[[  8.44475793]\n",
      " [  8.44475793]\n",
      " [-12.75314898]]\n",
      "Final weights\n",
      "[[  8.47897826]\n",
      " [  8.47897826]\n",
      " [-12.8044471 ]]\n",
      "[0.98453377]\n",
      "Random weights init\n",
      "[[  8.47897826]\n",
      " [  8.47897826]\n",
      " [-12.8044471 ]]\n",
      "Final weights\n",
      "[[10.44775861]\n",
      " [10.44775861]\n",
      " [-8.86876558]]\n",
      "[0.99999402]\n",
      "Initial hidden weights: [1, -1] [1, -1]\n",
      "Initial hidden biases: 1 1\n",
      "Initial output weights: [[0.30233257]\n",
      " [0.14675589]]\n",
      "Initial output biases: [[0.09233859]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 130>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m hidden_layer_activation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(inputs, hidden_weights)\n\u001b[0;32m    132\u001b[0m hidden_layer_activation \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m hidden_bias\n\u001b[1;32m--> 133\u001b[0m hidden_layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mthreshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_layer_activation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m output_layer_activation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot (hidden_layer_output, output_weights)\n\u001b[0;32m    135\u001b[0m output_layer_activation \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m output_bias\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mthreshold\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mthreshold\u001b[39m (x):\n\u001b[1;32m--> 101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    103\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"1_Perceptron_MLP.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1CCjaTOwfw_rfrlEYD2yl03VA3BVpn8vk\n",
    "\n",
    "# Code to implement Perceptron and Multi layer Perceptron and to train them on AND and OR Data sets\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork():\n",
    "  def __init__(self):\n",
    "\n",
    "    np.random.seed(1)\n",
    "    self.weights = 2 *np.random.random((3,1)) - 1\n",
    "\n",
    "  def sigmoid(self,x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "  def sigmoid_derivative(self,x):\n",
    "    return x * (1-x)\n",
    "\n",
    "  def train(self, training_inputs,training_outputs, training_iterations):\n",
    "\n",
    "    for iteration in range(training_iterations):\n",
    "\n",
    "      output = self.nn(training_inputs)\n",
    "\n",
    "      error = training_outputs - output\n",
    "\n",
    "      adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
    "\n",
    "      self.weights += adjustments\n",
    "\n",
    "  def nn(self,inputs):\n",
    "    inputs = inputs.astype(float)\n",
    "    output = self.sigmoid(np.dot(inputs, self.weights))\n",
    "    return output\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "  neural_network = NeuralNetwork()\n",
    "\n",
    "  print(\"Begining With Randomly Generated Weights\")\n",
    "  print(neural_network.weights)\n",
    "\n",
    "  training_inputs = np.array([[0,0,1],\n",
    "                              [1,1,1],\n",
    "                              [1,0,1],\n",
    "                              [0,1,1]])\n",
    "  training_outputs = np.array([[0,1,0,0]]).T\n",
    "\n",
    "  neural_network.train(training_inputs,training_outputs,15000)\n",
    "\n",
    "  print(\"Weights After Training : \")\n",
    "  print(neural_network.weights)\n",
    "  print(\"New Output Data : \")\n",
    "  print(neural_network.nn(np.array([1,1,1])))\n",
    "\n",
    "\"\"\"#For AND Data Set\"\"\"\n",
    "\n",
    "nn = neural_network\n",
    "print(\"Random weights init\")\n",
    "print(nn.weights)\n",
    "train_inp = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "train_out = np.array([[0,0,0,1]]).T\n",
    "nn.train(train_inp, train_out, 500)\n",
    "print(\"Final weights\")\n",
    "print(nn.weights)\n",
    "print(nn.nn(np.array([1,1,1])))\n",
    "\n",
    "\"\"\"#For OR Data Set\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "nn = neural_network\n",
    "print(\"Random weights init\")\n",
    "print(nn.weights)\n",
    "train_inp = np.array([[0,0,1],[1,1,1],[1,0,1],[0,1,1]])\n",
    "train_out = np.array([[0,1,1,1]]).T\n",
    "nn.train(train_inp, train_out, 40)\n",
    "print(\"Final weights\")\n",
    "print(nn.weights)\n",
    "\n",
    "print(nn.nn(np.array([1,1,1])))\n",
    "\n",
    "\"\"\"# MLP\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np #np.random. seed()\n",
    "\n",
    "def sigmoid (x): return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x): return x * (1 - x)\n",
    "\n",
    "def threshold (x):\n",
    "  if x>1:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "#Input datasets\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "epochs = 1\n",
    "lr = 0.1\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
    "\n",
    "#Random weights and bias initialization\n",
    "#hidden_weights = np.random.uniform( size=(inputLayerNeurons, hiddenLayerNeurons))\n",
    "hidden_weights=[[1,-1],[1,-1]]\n",
    "#hidden_bias =np.random.uniform(size=(1, hiddenLayerNeurons))\n",
    "hidden_bias=[1,1]\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons, outputLayerNeurons) )\n",
    "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
    "\n",
    "print(\"Initial hidden weights: \", end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \", end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \", end='')\n",
    "print(output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(output_bias)\n",
    "\n",
    "#Training algorithm\n",
    "for _ in range(epochs):\n",
    "    hidden_layer_activation = np.dot(inputs, hidden_weights)\n",
    "    hidden_layer_activation += hidden_bias\n",
    "    hidden_layer_output = threshold(hidden_layer_activation)\n",
    "    output_layer_activation = np.dot (hidden_layer_output, output_weights)\n",
    "    output_layer_activation += output_bias\n",
    "    predicted_output = threshold(output_layer_activation)\n",
    "\n",
    "    #error = expected_output - predicted_output\n",
    "    #d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "\n",
    "    #error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "    #d_hidden_layer =  error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "    output_bias += np.sum(d_predicted_output, axis=0, keepdims=True) * lr\n",
    "\n",
    "    #hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "    #hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * lr\n",
    "\n",
    "print(\"Initial hidden weights: \", end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \", end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \", end='')\n",
    "print(output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(output_bias)\n",
    "\n",
    "print(predicted_output)\n",
    "\n",
    "import numpy as np #np.random. seed()\n",
    "\n",
    "\n",
    "\n",
    "def threshold (x):\n",
    "  if x>1:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "#Input datasets\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Random weights and bias initialization\n",
    "hidden_weights = np.array([[1,-1],[-1,1]])\n",
    "hidden_bias =np.array([1,1,1,1])\n",
    "output_weights = [2,2]\n",
    "output_bias = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Initial hidden weights: \", end='')\n",
    "print(hidden_weights)\n",
    "print(\"Initial hidden biases: \", end='')\n",
    "print(hidden_bias)\n",
    "print(\"Initial output weights: \", end='')\n",
    "print(output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(output_bias)\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "  print(\"Input combination \",i+1)\n",
    "  hidden_layer1=inputs[i][0]*hidden_weights[0][0]+inputs[i][1]*hidden_weights[0][1]+1\n",
    "  print(\"Hidden layer neuron 1 : \",hidden_layer1)\n",
    "  hidden_layer_activation1=threshold(hidden_layer1)\n",
    "  print(\"After threshold \",hidden_layer_activation1)\n",
    "  hidden_layer2=inputs[i][0]*hidden_weights[1][0]+inputs[i][1]*hidden_weights[1][1]+1\n",
    "  print(\"Hidden layer neuron 2 : \",hidden_layer2)\n",
    "  hidden_layer_activation2=threshold(hidden_layer2)\n",
    "  print(\"After threshold \",hidden_layer_activation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define inputs\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "\n",
    "# Define weights and biases for the first hidden layer\n",
    "w1 = 1\n",
    "w2 = -1\n",
    "b1 = 1\n",
    "\n",
    "# Calculate the first hidden layer output (h1)\n",
    "h1 = np.maximum(X[:, 0] * w1 + X[:, 1] * w2 + b1, 0)\n",
    "\n",
    "# Print the first hidden layer output\n",
    "print(\"First Hidden Layer Output:\")\n",
    "for i in range(len(X)):\n",
    "    print(\"Input:\", X[i], \"Output:\", h1[i])\n",
    "\n",
    "# Define weights and biases for the second hidden layer\n",
    "w3 = -1\n",
    "w4 = 1\n",
    "b2 = 1\n",
    "\n",
    "# Calculate the second hidden layer output (h2)\n",
    "h2 = np.maximum(h1 * w3 + X[:, 1] * w4 + b2, 0)\n",
    "\n",
    "# Print the second hidden layer output\n",
    "print(\"\\nSecond Hidden Layer Output:\")\n",
    "for i in range(len(X)):\n",
    "    print(\"Input:\", X[i], \"Output:\", h2[i])\n",
    "\n",
    "# Define expected output\n",
    "expected_output = np.array([0, 1, 1, 0], dtype=np.float32)\n",
    "\n",
    "# Calculate the final output using an activation function\n",
    "output = np.where(h2 >= 0.5, 1, 0)\n",
    "\n",
    "# Print the final output\n",
    "print(\"\\nFinal Output:\")\n",
    "for i in range(len(X)):\n",
    "    print(\"Input:\", X[i], \"Output:\", output[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c870d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define inputs\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "\n",
    "# Define weights and biases for the first hidden layer\n",
    "w1 = 1\n",
    "w2 = -1\n",
    "b1 = 1\n",
    "\n",
    "# Calculate the first hidden layer output (h1)\n",
    "h1 = np.maximum(X[:, 0] * w1 + X[:, 1] * w2 + b1, 0)\n",
    "\n",
    "# Print the first hidden layer output\n",
    "print(\"First Hidden Layer Output:\")\n",
    "for i in range(len(X)):\n",
    "    print(\"Input:\", X[i], \"Output:\", h1[i])\n",
    "\n",
    "# Define weights and biases for the second hidden layer\n",
    "w3 = -1\n",
    "w4 = 1\n",
    "b2 = 1\n",
    "\n",
    "# Calculate the second hidden layer output (h2)\n",
    "h2 = np.maximum(X[:, 0] * w3 + X[:, 1] * w4 + b2, 0)\n",
    "\n",
    "# Print the second hidden layer output\n",
    "print(\"\\nSecond Hidden Layer Output:\")\n",
    "for i in range(len(X)):\n",
    "    print(\"Input:\", X[i], \"Output:\", h2[i])\n",
    "\n",
    "# Define weights and bias for the output layer\n",
    "w5 = 2\n",
    "w6 = 2\n",
    "b3 = -3\n",
    "\n",
    "# Calculate the output (y)\n",
    "output = np.where(h1 * w5 + h2 * w6 + b3 >= 0, 1, 0)\n",
    "\n",
    "# Print the final output\n",
    "print(\"\\nFinal Output:\")\n",
    "for i in range(len(X)):\n",
    "    print(\"Input:\", X[i], \"Output:\", output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf891505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_activation(value, threshold):\n",
    "    if value >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Define the weights and biases\n",
    "weights_x1 = [1, -1]\n",
    "weights_x2 = [-1, 1]\n",
    "bias_h1 = 1\n",
    "bias_h2 = 1\n",
    "weights_h1 = 2\n",
    "weights_h2 = 2\n",
    "bias_h3 = 1\n",
    "threshold = 5  # Set the threshold value\n",
    "\n",
    "# Calculate the values of the hidden layers\n",
    "x1 = 1\n",
    "x2 = -1\n",
    "\n",
    "h1 = (weights_h1 * x1) + (weights_h1 * x2) + bias_h1\n",
    "h2 = (weights_h2 * x1) + (weights_h2 * x2) + bias_h2\n",
    "\n",
    "# Calculate the value of the output layer (H3)\n",
    "h3 = (weights_h1 * h1) + (weights_h2 * h2) + bias_h3\n",
    "\n",
    "# Apply the threshold activation function to get the output (y)\n",
    "y = threshold_activation(h3, threshold)\n",
    "\n",
    "# Print the results\n",
    "print(\"Hidden Layer H1:\", h1)\n",
    "print(\"Hidden Layer H2:\", h2)\n",
    "print(\"Output (y):\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c681654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96321d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "#np.random.seed(0)\n",
    "\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "#Input datasets\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "epochs = 10000\n",
    "lr = 0.1\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
    "\n",
    "#Random weights and bias initialization\n",
    "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
    "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
    "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
    "\n",
    "print(\"Initial hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "\n",
    "#Training algorithm\n",
    "for _ in range(epochs):\n",
    "\t#Forward Propagation\n",
    "\thidden_layer_activation = np.dot(inputs,hidden_weights)\n",
    "\thidden_layer_activation += hidden_bias\n",
    "\thidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "\toutput_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
    "\toutput_layer_activation += output_bias\n",
    "\tpredicted_output = sigmoid(output_layer_activation)\n",
    "\n",
    "\t#Backpropagation\n",
    "\terror = expected_output - predicted_output\n",
    "\td_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "\t\n",
    "\terror_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "\td_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "\t#Updating Weights and Biases\n",
    "\toutput_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "\toutput_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
    "\thidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "\thidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
    "\n",
    "print(\"Final hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Final hidden bias: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Final output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Final output bias: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
    "print(*predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2822b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1b045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd97b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f48a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
