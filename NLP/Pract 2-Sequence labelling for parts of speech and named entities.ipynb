{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f873e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f620ba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'MD', 'RB', 'DT', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob * observation_probs[j, i]\n",
    "        backpointer[i, j] = max_index\n",
    "\n",
    "# Step 3: Perform backtracking to find the most likely sequence\n",
    "best_path_prob = np.max(viterbi[-1])\n",
    "best_path_end_tag = np.argmax(viterbi[-1])\n",
    "best_path = [best_path_end_tag]\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    best_path_end_tag = backpointer[i, best_path_end_tag]\n",
    "    best_path.insert(0, best_path_end_tag)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0728f656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35ac6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOUN', 'VERB', 'ADV', 'PRON', 'PROPN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NOUN', 'VERB', 'DET', 'ADP', 'PROPN', 'ADV', 'PRON']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2 and 3: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j] * observation_probs[j, i]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob\n",
    "        backpointer[i, j] = max_index\n",
    "\n",
    "# Step 4: Perform backtracking to find the most likely sequence\n",
    "best_path_prob = np.max(viterbi[-1])\n",
    "best_path_end_tag = np.argmax(viterbi[-1])\n",
    "best_path = [best_path_end_tag]\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    best_path_end_tag = backpointer[i, best_path_end_tag]\n",
    "    best_path.insert(0, best_path_end_tag)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcfa410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b3263c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'MD', 'VB', 'DT', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2 and 3: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j] * observation_probs[j, i]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob\n",
    "        backpointer[i, j] = max_index\n",
    "\n",
    "# Step 4: Perform backtracking to find the most likely sequence\n",
    "best_path_prob = np.max(viterbi[-1])\n",
    "best_path_end_tag = np.argmax(viterbi[-1])\n",
    "best_path = [best_path_end_tag]\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    best_path_end_tag = backpointer[i, best_path_end_tag]\n",
    "    best_path.insert(0, best_path_end_tag)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ef988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fdee6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'MD', 'RB', 'VB', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = transition_probs[j, 0] * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2 and 3: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j] * observation_probs[j, i]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob\n",
    "        backpointer[i, j] = max_index\n",
    "\n",
    "# Step 4: Perform backtracking to find the most likely sequence\n",
    "best_path = []\n",
    "max_prob_index = np.argmax(viterbi[-1])\n",
    "best_path.insert(0, max_prob_index)\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    max_prob_index = backpointer[i, max_prob_index]\n",
    "    best_path.insert(0, max_prob_index)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95b6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc79a4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'MD', 'RB', 'DT', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2 and 3: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j] * observation_probs[j, i]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob\n",
    "        backpointer[i, j] = max_index\n",
    "\n",
    "# Step 4: Perform backtracking to find the most likely sequence\n",
    "best_path = []\n",
    "max_prob_index = np.argmax(viterbi[-1])\n",
    "best_path.insert(0, max_prob_index)\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    max_prob_index = backpointer[i, max_prob_index]\n",
    "    best_path.insert(0, max_prob_index)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722ecf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9b796e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'MD', 'NN', 'NNP', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'DT', 'NN']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2 and 3: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j] * observation_probs[j, i]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob\n",
    "        backpointer[i, j] = max_index\n",
    "\n",
    "# Step 4: Perform backtracking to find the most likely sequence\n",
    "best_path_prob = np.max(viterbi[-1])\n",
    "best_path_end_tag = np.argmax(viterbi[-1])\n",
    "best_path = [best_path_end_tag]\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    best_path_end_tag = backpointer[i, best_path_end_tag]\n",
    "    best_path.insert(0, best_path_end_tag)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920cdd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56bc050f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8,) (7,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 69>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m     obs_indices\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mwhere(obs \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJanet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbill\u001b[39m\u001b[38;5;124m'\u001b[39m]))[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Perform Viterbi decoding\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m best_path \u001b[38;5;241m=\u001b[39m \u001b[43mviterbi_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransition_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Map the indices back to the corresponding tags\u001b[39;00m\n\u001b[0;32m     72\u001b[0m tags \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVERB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDET\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mviterbi_decode\u001b[1;34m(observations, observation_probs, transition_probs, initial_probs)\u001b[0m\n\u001b[0;32m      9\u001b[0m backpointers \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_states, sequence_length), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Initialize the first column of the trellis with initial probabilities\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m trellis[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43minitial_probs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobservation_probs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Iterate over the remaining columns\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, sequence_length):\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (8,) (7,) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def viterbi_decode(observations, observation_probs, transition_probs, initial_probs):\n",
    "    num_states = len(initial_probs)\n",
    "    sequence_length = len(observations)\n",
    "    \n",
    "    # Initialize the trellis with zeros\n",
    "    trellis = np.zeros((num_states, sequence_length))\n",
    "    backpointers = np.zeros((num_states, sequence_length), dtype=int)\n",
    "    \n",
    "    # Initialize the first column of the trellis with initial probabilities\n",
    "    trellis[:, 0] = initial_probs * observation_probs[:, observations[0]]\n",
    "    \n",
    "    # Iterate over the remaining columns\n",
    "    for t in range(1, sequence_length):\n",
    "        for s in range(num_states):\n",
    "            # Calculate the probabilities for each state at time t\n",
    "            probabilities = trellis[:, t - 1] * transition_probs[:, s] * observation_probs[s, observations[t]]\n",
    "            \n",
    "            # Find the maximum probability and its corresponding backpointer\n",
    "            max_probability = np.max(probabilities)\n",
    "            argmax_probability = np.argmax(probabilities)\n",
    "            \n",
    "            # Update the trellis and backpointers\n",
    "            trellis[s, t] = max_probability\n",
    "            backpointers[s, t] = argmax_probability\n",
    "    \n",
    "    # Perform backtracking to find the best path\n",
    "    best_path = []\n",
    "    best_path.append(np.argmax(trellis[:, -1]))\n",
    "    \n",
    "    for t in range(sequence_length - 1, 0, -1):\n",
    "        best_path.insert(0, backpointers[best_path[0], t])\n",
    "    \n",
    "    return best_path\n",
    "\n",
    "# Example usage\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026, 0],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025, 0],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041, 0],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231, 0],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036, 0],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068, 0],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479, 0],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017, 0]\n",
    "])\n",
    "\n",
    "initial_probs = np.array([0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026, 0])\n",
    "\n",
    "observations = ['Janet', 'will', 'back', 'the', 'bill']\n",
    "\n",
    "# Convert the observations to their corresponding indices\n",
    "obs_indices = []\n",
    "for obs in observations:\n",
    "    obs_indices.append(np.where(obs == np.array(['Janet', 'will', 'back', 'the', 'bill']))[0][0])\n",
    "\n",
    "# Perform Viterbi decoding\n",
    "best_path = viterbi_decode(obs_indices, observation_probs, transition_probs, initial_probs)\n",
    "\n",
    "# Map the indices back to the corresponding tags\n",
    "tags = ['NOUN', 'VERB', 'ADV', 'DET', 'NOUN']\n",
    "predicted_tags = [tags[i] for i in best_path]\n",
    "\n",
    "# Print the predicted tags\n",
    "print(predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edb45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae85d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20d707a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the query: why hello why there\n",
      "['why', 'why']\n",
      "['hello', 'there']\n",
      "3\n",
      "7\n",
      "   hello  omg  pony  she  there  went  why\n",
      "0      1    0     0    0      1     0    1\n",
      "1      1    1     1    0      0     0    0\n",
      "2      0    1     0    1      1     1    0\n",
      "[[0.0, 0.0, 0.0]]\n",
      "Total documents: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "docs = ['why hello why there', 'omg hello pony', 'she went there omg']\n",
    "\n",
    "vec = CountVectorizer()\n",
    "x = vec.fit_transform(docs)\n",
    "\n",
    "df = pd.DataFrame(x.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "query = input(\"Enter the query: \")\n",
    "list2 = query.split()\n",
    "list3 = []\n",
    "list4 = []\n",
    "\n",
    "for i in range(len(list2)):\n",
    "    if i % 2 == 0:\n",
    "        list3.append(list2[i])\n",
    "    else:\n",
    "        list4.append(list2[i])\n",
    "print(list3)\n",
    "print(list4)\n",
    "\n",
    "x = []\n",
    "print(df.shape[0])\n",
    "print(df.shape[1])\n",
    "\n",
    "for i in range(df.shape[0] - 1):\n",
    "    for j in range(df.shape[1]):\n",
    "        if df.loc[i][j] > 1:\n",
    "            df.loc[i][j] = 1\n",
    "print(df)\n",
    "\n",
    "k = list4[0]\n",
    "ans = np.zeros(df.shape[0])  # Initialize ans as an array of zeros\n",
    "\n",
    "if k == '&':\n",
    "    ans = np.bitwise_and(df.loc[:, list3[0]], df.loc[:, list3[1]])\n",
    "if k == '|':\n",
    "    ans = np.bitwise_or(df.loc[:, list3[0]], df.loc[:, list3[1]])\n",
    "\n",
    "l = list4[1]\n",
    "if l == '&':\n",
    "    ans = np.bitwise_and(df.loc[:, list3[0]], ans)\n",
    "if l == '|':\n",
    "    ans = np.bitwise_or(df.loc[:, list3[0]], ans)\n",
    "\n",
    "ans1 = [ans]\n",
    "list6 = []\n",
    "\n",
    "for i in range(len(ans1)):\n",
    "    ans1[i] = list(ans1[i])\n",
    "print(ans1)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(ans1[0])):\n",
    "    if ans1[0][i] == 1:\n",
    "        count += 1\n",
    "        print(\"Present in Document Number:\", i)\n",
    "\n",
    "print(\"Total documents:\", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fddad5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature Matrix:\n",
      "  T1  T2  T3\n",
      "I'm good. [5, 1]\n",
      "Let's catch up soon. [5, 1]\n",
      "Hello, how are you? [2, 1]\n",
      "I'm fine. [2, 1]\n",
      "What are your plans for today? [2, 4]\n",
      "I am doing great. [2, 4]\n",
      "Any exciting plans for the weekend? [5, 1]\n",
      "Hi there! [5, 1]\n",
      "Hey! [2, 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Create lists of sentences for each document\n",
    "doc1 = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"I am doing great.\",\n",
    "    \"What are your plans for today?\"\n",
    "]\n",
    "\n",
    "doc2 = [\n",
    "    \"Hi there!\",\n",
    "    \"I'm fine.\",\n",
    "    \"Any exciting plans for the weekend?\"\n",
    "]\n",
    "\n",
    "doc3 = [\n",
    "    \"Hey!\",\n",
    "    \"I'm good.\",\n",
    "    \"Let's catch up soon.\"\n",
    "]\n",
    "\n",
    "# Define the number of hash functions\n",
    "num_hash_functions = 2\n",
    "\n",
    "# Generate a set of random hash functions\n",
    "hash_functions = []\n",
    "for _ in range(num_hash_functions):\n",
    "    a = random.randint(1, 100)\n",
    "    b = random.randint(1, 100)\n",
    "    hash_functions.append((a, b))\n",
    "\n",
    "# Create a set of unique words across all documents\n",
    "words = set()\n",
    "words.update(*[doc1, doc2, doc3])\n",
    "\n",
    "# Create the signature matrix\n",
    "signature_matrix = []\n",
    "for word in words:\n",
    "    signature = []\n",
    "    for hash_function in hash_functions:\n",
    "        min_hash = float('inf')\n",
    "        for doc in [doc1, doc2, doc3]:\n",
    "            # Calculate the hash value using a simple hash function based on ASCII values\n",
    "            hash_value = sum(ord(c) for sentence in doc for c in sentence) + sum(ord(c) for c in word)\n",
    "            hash_value = (hash_function[0] * hash_value + hash_function[1]) % len(words)\n",
    "            min_hash = min(min_hash, hash_value)\n",
    "        signature.append(min_hash)\n",
    "    signature_matrix.append(signature)\n",
    "\n",
    "# Display the signature matrix\n",
    "print(\"Signature Matrix:\")\n",
    "print(\"  T1  T2  T3\")\n",
    "for i, word in enumerate(words):\n",
    "    print(f\"{word} {signature_matrix[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cbadf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16aa2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2f5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf694e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
