{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'MD', 'RB', 'DT', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob * observation_probs[j, i]\n",
    "        backpointer[i, j] = max_index\n",
    "\n",
    "# Step 3: Perform backtracking to find the most likely sequence\n",
    "best_path_prob = np.max(viterbi[-1])\n",
    "best_path_end_tag = np.argmax(viterbi[-1])\n",
    "best_path = [best_path_end_tag]\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    best_path_end_tag = backpointer[i, best_path_end_tag]\n",
    "    best_path.insert(0, best_path_end_tag)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOUN', 'VERB', 'ADV', 'PRON', 'PROPN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NOUN', 'VERB', 'DET', 'ADP', 'PROPN', 'ADV', 'PRON']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2 and 3: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j] * observation_probs[j, i]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob\n",
    "        backpointer[i, j] = max_index\n",
    "\n",
    "# Step 4: Perform backtracking to find the most likely sequence\n",
    "best_path_prob = np.max(viterbi[-1])\n",
    "best_path_end_tag = np.argmax(viterbi[-1])\n",
    "best_path = [best_path_end_tag]\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    best_path_end_tag = backpointer[i, best_path_end_tag]\n",
    "    best_path.insert(0, best_path_end_tag)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 3,
   "id": "6b3263c0",
>>>>>>> c5c03632b0ff71bccd9bb691557ccae9c7db1e13
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'MD', 'VB', 'DT', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2 and 3: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j] * observation_probs[j, i]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob\n",
    "        backpointer[i, j] = max_index\n",
    "\n",
    "# Step 4: Perform backtracking to find the most likely sequence\n",
    "best_path_prob = np.max(viterbi[-1])\n",
    "best_path_end_tag = np.argmax(viterbi[-1])\n",
    "best_path = [best_path_end_tag]\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    best_path_end_tag = backpointer[i, best_path_end_tag]\n",
    "    best_path.insert(0, best_path_end_tag)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'MD', 'RB', 'VB', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = transition_probs[j, 0] * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2 and 3: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j] * observation_probs[j, i]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob\n",
    "        backpointer[i, j] = max_index\n",
    "\n",
    "# Step 4: Perform backtracking to find the most likely sequence\n",
    "best_path = []\n",
    "max_prob_index = np.argmax(viterbi[-1])\n",
    "best_path.insert(0, max_prob_index)\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    max_prob_index = backpointer[i, max_prob_index]\n",
    "    best_path.insert(0, max_prob_index)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'MD', 'RB', 'DT', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2 and 3: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j] * observation_probs[j, i]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob\n",
    "        backpointer[i, j] = max_index\n",
    "\n",
    "# Step 4: Perform backtracking to find the most likely sequence\n",
    "best_path = []\n",
    "max_prob_index = np.argmax(viterbi[-1])\n",
    "best_path.insert(0, max_prob_index)\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    max_prob_index = backpointer[i, max_prob_index]\n",
    "    best_path.insert(0, max_prob_index)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'MD', 'NN', 'NNP', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'DT', 'NN']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2 and 3: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j] * observation_probs[j, i]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob\n",
    "        backpointer[i, j] = max_index\n",
    "\n",
    "# Step 4: Perform backtracking to find the most likely sequence\n",
    "best_path_prob = np.max(viterbi[-1])\n",
    "best_path_end_tag = np.argmax(viterbi[-1])\n",
    "best_path = [best_path_end_tag]\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    best_path_end_tag = backpointer[i, best_path_end_tag]\n",
    "    best_path.insert(0, best_path_end_tag)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8,) (7,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 69>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m     obs_indices\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mwhere(obs \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJanet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbill\u001b[39m\u001b[38;5;124m'\u001b[39m]))[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Perform Viterbi decoding\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m best_path \u001b[38;5;241m=\u001b[39m \u001b[43mviterbi_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransition_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Map the indices back to the corresponding tags\u001b[39;00m\n\u001b[0;32m     72\u001b[0m tags \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVERB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDET\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mviterbi_decode\u001b[1;34m(observations, observation_probs, transition_probs, initial_probs)\u001b[0m\n\u001b[0;32m      9\u001b[0m backpointers \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_states, sequence_length), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Initialize the first column of the trellis with initial probabilities\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m trellis[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43minitial_probs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobservation_probs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Iterate over the remaining columns\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, sequence_length):\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (8,) (7,) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def viterbi_decode(observations, observation_probs, transition_probs, initial_probs):\n",
    "    num_states = len(initial_probs)\n",
    "    sequence_length = len(observations)\n",
    "    \n",
    "    # Initialize the trellis with zeros\n",
    "    trellis = np.zeros((num_states, sequence_length))\n",
    "    backpointers = np.zeros((num_states, sequence_length), dtype=int)\n",
    "    \n",
    "    # Initialize the first column of the trellis with initial probabilities\n",
    "    trellis[:, 0] = initial_probs * observation_probs[:, observations[0]]\n",
    "    \n",
    "    # Iterate over the remaining columns\n",
    "    for t in range(1, sequence_length):\n",
    "        for s in range(num_states):\n",
    "            # Calculate the probabilities for each state at time t\n",
    "            probabilities = trellis[:, t - 1] * transition_probs[:, s] * observation_probs[s, observations[t]]\n",
    "            \n",
    "            # Find the maximum probability and its corresponding backpointer\n",
    "            max_probability = np.max(probabilities)\n",
    "            argmax_probability = np.argmax(probabilities)\n",
    "            \n",
    "            # Update the trellis and backpointers\n",
    "            trellis[s, t] = max_probability\n",
    "            backpointers[s, t] = argmax_probability\n",
    "    \n",
    "    # Perform backtracking to find the best path\n",
    "    best_path = []\n",
    "    best_path.append(np.argmax(trellis[:, -1]))\n",
    "    \n",
    "    for t in range(sequence_length - 1, 0, -1):\n",
    "        best_path.insert(0, backpointers[best_path[0], t])\n",
    "    \n",
    "    return best_path\n",
    "\n",
    "# Example usage\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026, 0],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025, 0],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041, 0],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231, 0],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036, 0],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068, 0],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479, 0],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017, 0]\n",
    "])\n",
    "\n",
    "initial_probs = np.array([0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026, 0])\n",
    "\n",
    "observations = ['Janet', 'will', 'back', 'the', 'bill']\n",
    "\n",
    "# Convert the observations to their corresponding indices\n",
    "obs_indices = []\n",
    "for obs in observations:\n",
    "    obs_indices.append(np.where(obs == np.array(['Janet', 'will', 'back', 'the', 'bill']))[0][0])\n",
    "\n",
    "# Perform Viterbi decoding\n",
    "best_path = viterbi_decode(obs_indices, observation_probs, transition_probs, initial_probs)\n",
    "\n",
    "# Map the indices back to the corresponding tags\n",
    "tags = ['NOUN', 'VERB', 'ADV', 'DET', 'NOUN']\n",
    "predicted_tags = [tags[i] for i in best_path]\n",
    "\n",
    "# Print the predicted tags\n",
    "print(predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the query: why hello why there\n",
      "['why', 'why']\n",
      "['hello', 'there']\n",
      "3\n",
      "7\n",
      "   hello  omg  pony  she  there  went  why\n",
      "0      1    0     0    0      1     0    1\n",
      "1      1    1     1    0      0     0    0\n",
      "2      0    1     0    1      1     1    0\n",
      "[[0.0, 0.0, 0.0]]\n",
      "Total documents: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "docs = ['why hello why there', 'omg hello pony', 'she went there omg']\n",
    "\n",
    "vec = CountVectorizer()\n",
    "x = vec.fit_transform(docs)\n",
    "\n",
    "df = pd.DataFrame(x.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "query = input(\"Enter the query: \")\n",
    "list2 = query.split()\n",
    "list3 = []\n",
    "list4 = []\n",
    "\n",
    "for i in range(len(list2)):\n",
    "    if i % 2 == 0:\n",
    "        list3.append(list2[i])\n",
    "    else:\n",
    "        list4.append(list2[i])\n",
    "print(list3)\n",
    "print(list4)\n",
    "\n",
    "x = []\n",
    "print(df.shape[0])\n",
    "print(df.shape[1])\n",
    "\n",
    "for i in range(df.shape[0] - 1):\n",
    "    for j in range(df.shape[1]):\n",
    "        if df.loc[i][j] > 1:\n",
    "            df.loc[i][j] = 1\n",
    "print(df)\n",
    "\n",
    "k = list4[0]\n",
    "ans = np.zeros(df.shape[0])  # Initialize ans as an array of zeros\n",
    "\n",
    "if k == '&':\n",
    "    ans = np.bitwise_and(df.loc[:, list3[0]], df.loc[:, list3[1]])\n",
    "if k == '|':\n",
    "    ans = np.bitwise_or(df.loc[:, list3[0]], df.loc[:, list3[1]])\n",
    "\n",
    "l = list4[1]\n",
    "if l == '&':\n",
    "    ans = np.bitwise_and(df.loc[:, list3[0]], ans)\n",
    "if l == '|':\n",
    "    ans = np.bitwise_or(df.loc[:, list3[0]], ans)\n",
    "\n",
    "ans1 = [ans]\n",
    "list6 = []\n",
    "\n",
    "for i in range(len(ans1)):\n",
    "    ans1[i] = list(ans1[i])\n",
    "print(ans1)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(ans1[0])):\n",
    "    if ans1[0][i] == 1:\n",
    "        count += 1\n",
    "        print(\"Present in Document Number:\", i)\n",
    "\n",
    "print(\"Total documents:\", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature Matrix:\n",
      "  T1  T2  T3\n",
      "I'm good. [5, 1]\n",
      "Let's catch up soon. [5, 1]\n",
      "Hello, how are you? [2, 1]\n",
      "I'm fine. [2, 1]\n",
      "What are your plans for today? [2, 4]\n",
      "I am doing great. [2, 4]\n",
      "Any exciting plans for the weekend? [5, 1]\n",
      "Hi there! [5, 1]\n",
      "Hey! [2, 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Create lists of sentences for each document\n",
    "doc1 = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"I am doing great.\",\n",
    "    \"What are your plans for today?\"\n",
    "]\n",
    "\n",
    "doc2 = [\n",
    "    \"Hi there!\",\n",
    "    \"I'm fine.\",\n",
    "    \"Any exciting plans for the weekend?\"\n",
    "]\n",
    "\n",
    "doc3 = [\n",
    "    \"Hey!\",\n",
    "    \"I'm good.\",\n",
    "    \"Let's catch up soon.\"\n",
    "]\n",
    "\n",
    "# Define the number of hash functions\n",
    "num_hash_functions = 2\n",
    "\n",
    "# Generate a set of random hash functions\n",
    "hash_functions = []\n",
    "for _ in range(num_hash_functions):\n",
    "    a = random.randint(1, 100)\n",
    "    b = random.randint(1, 100)\n",
    "    hash_functions.append((a, b))\n",
    "\n",
    "# Create a set of unique words across all documents\n",
    "words = set()\n",
    "words.update(*[doc1, doc2, doc3])\n",
    "\n",
    "# Create the signature matrix\n",
    "signature_matrix = []\n",
    "for word in words:\n",
    "    signature = []\n",
    "    for hash_function in hash_functions:\n",
    "        min_hash = float('inf')\n",
    "        for doc in [doc1, doc2, doc3]:\n",
    "            # Calculate the hash value using a simple hash function based on ASCII values\n",
    "            hash_value = sum(ord(c) for sentence in doc for c in sentence) + sum(ord(c) for c in word)\n",
    "            hash_value = (hash_function[0] * hash_value + hash_function[1]) % len(words)\n",
    "            min_hash = min(min_hash, hash_value)\n",
    "        signature.append(min_hash)\n",
    "    signature_matrix.append(signature)\n",
    "\n",
    "# Display the signature matrix\n",
    "print(\"Signature Matrix:\")\n",
    "print(\"  T1  T2  T3\")\n",
    "for i, word in enumerate(words):\n",
    "    print(f\"{word} {signature_matrix[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viterbi[1, 0] = 0.0000089 * 0.0000000 = 0.0000000\n",
      "Backpointer[1, 0] = 0\n",
      "Viterbi[1, 1] = 0.0000000 * 0.3084310 = 0.0000000\n",
      "Backpointer[1, 1] = 0\n",
      "Viterbi[1, 2] = 0.0000001 * 0.0000280 = 0.0000000\n",
      "Backpointer[1, 2] = 0\n",
      "Viterbi[1, 3] = 0.0000014 * 0.0000000 = 0.0000000\n",
      "Backpointer[1, 3] = 0\n",
      "Viterbi[1, 4] = 0.0000014 * 0.0002000 = 0.0000000\n",
      "Backpointer[1, 4] = 0\n",
      "Viterbi[1, 5] = 0.0000016 * 0.0000000 = 0.0000000\n",
      "Backpointer[1, 5] = 0\n",
      "Viterbi[1, 6] = 0.0000065 * 0.0000000 = 0.0000000\n",
      "Backpointer[1, 6] = 0\n",
      "Viterbi[2, 0] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[2, 0] = 1\n",
      "Viterbi[2, 1] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[2, 1] = 1\n",
      "Viterbi[2, 2] = 0.0000000 * 0.0006720 = 0.0000000\n",
      "Backpointer[2, 2] = 1\n",
      "Viterbi[2, 3] = 0.0000000 * 0.0003400 = 0.0000000\n",
      "Backpointer[2, 3] = 1\n",
      "Viterbi[2, 4] = 0.0000000 * 0.0002230 = 0.0000000\n",
      "Backpointer[2, 4] = 1\n",
      "Viterbi[2, 5] = 0.0000000 * 0.0104460 = 0.0000000\n",
      "Backpointer[2, 5] = 1\n",
      "Viterbi[2, 6] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[2, 6] = 1\n",
      "Viterbi[3, 0] = 0.0000000 * 0.0000480 = 0.0000000\n",
      "Backpointer[3, 0] = 5\n",
      "Viterbi[3, 1] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 1] = 5\n",
      "Viterbi[3, 2] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 2] = 2\n",
      "Viterbi[3, 3] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 3] = 4\n",
      "Viterbi[3, 4] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 4] = 5\n",
      "Viterbi[3, 5] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 5] = 5\n",
      "Viterbi[3, 6] = 0.0000000 * 0.5060990 = 0.0000000\n",
      "Backpointer[3, 6] = 5\n",
      "Viterbi[4, 0] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 0] = 6\n",
      "Viterbi[4, 1] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 1] = 6\n",
      "Viterbi[4, 2] = 0.0000000 * 0.0000280 = 0.0000000\n",
      "Backpointer[4, 2] = 6\n",
      "Viterbi[4, 3] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 3] = 6\n",
      "Viterbi[4, 4] = 0.0000000 * 0.0023370 = 0.0000000\n",
      "Backpointer[4, 4] = 6\n",
      "Viterbi[4, 5] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 5] = 6\n",
      "Viterbi[4, 6] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 6] = 6\n",
      "['NNP', 'MD', 'RB', 'DT', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob * observation_probs[j, i]\n",
    "        backpointer[i, j] = max_index\n",
    "        print(f\"Viterbi[{i}, {j}] = {max_prob:.7f} * {observation_probs[j, i]:.7f} = {viterbi[i, j]:.7f}\")\n",
    "        print(f\"Backpointer[{i}, {j}] = {max_index}\")\n",
    "\n",
    "# Step 3: Perform backtracking to find the most likely sequence\n",
    "best_path_prob = np.max(viterbi[-1])\n",
    "best_path_end_tag = np.argmax(viterbi[-1])\n",
    "best_path = [best_path_end_tag]\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    best_path_end_tag = backpointer[i, best_path_end_tag]\n",
    "    best_path.insert(0, best_path_end_tag)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current word: will\n",
      "Viterbi[1, 0] = 0.0000121 * 0.0000000 = 0.0000000\n",
      "Backpointer[1, 0] = NNP\n",
      "Viterbi[1, 1] = 0.0000004 * 0.3084310 = 0.0000001\n",
      "Backpointer[1, 1] = NNP\n",
      "Viterbi[1, 2] = 0.0000000 * 0.0000280 = 0.0000000\n",
      "Backpointer[1, 2] = NNP\n",
      "Viterbi[1, 3] = 0.0000003 * 0.0000000 = 0.0000000\n",
      "Backpointer[1, 3] = NNP\n",
      "Viterbi[1, 4] = 0.0000019 * 0.0002000 = 0.0000000\n",
      "Backpointer[1, 4] = NNP\n",
      "Viterbi[1, 5] = 0.0000003 * 0.0000000 = 0.0000000\n",
      "Backpointer[1, 5] = NNP\n",
      "Viterbi[1, 6] = 0.0000001 * 0.0000000 = 0.0000000\n",
      "Backpointer[1, 6] = NNP\n",
      "\n",
      "Current word: back\n",
      "Viterbi[2, 0] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[2, 0] = MD\n",
      "Viterbi[2, 1] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[2, 1] = MD\n",
      "Viterbi[2, 2] = 0.0000001 * 0.0006720 = 0.0000000\n",
      "Backpointer[2, 2] = MD\n",
      "Viterbi[2, 3] = 0.0000000 * 0.0003400 = 0.0000000\n",
      "Backpointer[2, 3] = MD\n",
      "Viterbi[2, 4] = 0.0000000 * 0.0002230 = 0.0000000\n",
      "Backpointer[2, 4] = MD\n",
      "Viterbi[2, 5] = 0.0000000 * 0.0104460 = 0.0000000\n",
      "Backpointer[2, 5] = MD\n",
      "Viterbi[2, 6] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[2, 6] = MD\n",
      "\n",
      "Current word: the\n",
      "Viterbi[3, 0] = 0.0000000 * 0.0000480 = 0.0000000\n",
      "Backpointer[3, 0] = VB\n",
      "Viterbi[3, 1] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 1] = RB\n",
      "Viterbi[3, 2] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 2] = RB\n",
      "Viterbi[3, 3] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 3] = RB\n",
      "Viterbi[3, 4] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 4] = VB\n",
      "Viterbi[3, 5] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 5] = RB\n",
      "Viterbi[3, 6] = 0.0000000 * 0.5060990 = 0.0000000\n",
      "Backpointer[3, 6] = VB\n",
      "\n",
      "Current word: bill\n",
      "Viterbi[4, 0] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 0] = DT\n",
      "Viterbi[4, 1] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 1] = DT\n",
      "Viterbi[4, 2] = 0.0000000 * 0.0000280 = 0.0000000\n",
      "Backpointer[4, 2] = DT\n",
      "Viterbi[4, 3] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 3] = DT\n",
      "Viterbi[4, 4] = 0.0000000 * 0.0023370 = 0.0000000\n",
      "Backpointer[4, 4] = DT\n",
      "Viterbi[4, 5] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 5] = DT\n",
      "Viterbi[4, 6] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 6] = DT\n",
      "\n",
      "Most likely sequence of POS tags:\n",
      "['NNP', 'MD', 'VB', 'DT', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "#     [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2: Perform the dynamic programming steps\n",
    "for i in range(1, num_words): \n",
    "    #This loop iterates over the words in the sentence, starting from the second word (index 1) since we have already computed the initial probabilities for the first word in the previous step.\n",
    "    print(f\"\\nCurrent word: {sentence.split()[i]}\")\n",
    "    for j in range(num_tags): #This inner loop iterates over each possible POS tag in the tags list.\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        # These variables are used to keep track of the maximum probability and the corresponding POS tag index during the calculations.\n",
    "        for k in range(num_tags):\n",
    "            # This nested loop iterates over each possible POS tag again to calculate the probabilities.\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob * observation_probs[j, i]\n",
    "        backpointer[i, j] = max_index\n",
    "        print(f\"Viterbi[{i}, {j}] = {max_prob:.7f} * {observation_probs[j, i]:.7f} = {viterbi[i, j]:.7f}\")\n",
    "        # print(f\"Viterbi[{i}, {j}] = {max_prob} * {observation_probs[j, i]} = {viterbi[i, j]}\")\n",
    "        print(f\"Backpointer[{i}, {j}] = {tags[max_index]}\")\n",
    "\n",
    "# Step 3: Perform backtracking to find the most likely sequence\n",
    "best_path_prob = np.max(viterbi[-1])\n",
    "best_path_end_tag = np.argmax(viterbi[-1])\n",
    "best_path = [best_path_end_tag]\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    best_path_end_tag = backpointer[i, best_path_end_tag]\n",
    "    best_path.insert(0, best_path_end_tag)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(\"\\nMost likely sequence of POS tags:\")\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current word: will\n",
      "Viterbi[1, 0] = 0.0000089 * 0.0000000 = 0.0000000\n",
      "Backpointer[1, 0] = NNP\n",
      "Probability for choosing tag 'NNP' at word 'will': 0.0000089\n",
      "Viterbi[1, 1] = 0.0000000 * 0.3084310 = 0.0000000\n",
      "Backpointer[1, 1] = NNP\n",
      "Probability for choosing tag 'MD' at word 'will': 0.0000000\n",
      "Viterbi[1, 2] = 0.0000001 * 0.0000280 = 0.0000000\n",
      "Backpointer[1, 2] = NNP\n",
      "Probability for choosing tag 'VB' at word 'will': 0.0000001\n",
      "Viterbi[1, 3] = 0.0000014 * 0.0000000 = 0.0000000\n",
      "Backpointer[1, 3] = NNP\n",
      "Probability for choosing tag 'JJ' at word 'will': 0.0000014\n",
      "Viterbi[1, 4] = 0.0000014 * 0.0002000 = 0.0000000\n",
      "Backpointer[1, 4] = NNP\n",
      "Probability for choosing tag 'NN' at word 'will': 0.0000014\n",
      "Viterbi[1, 5] = 0.0000016 * 0.0000000 = 0.0000000\n",
      "Backpointer[1, 5] = NNP\n",
      "Probability for choosing tag 'RB' at word 'will': 0.0000016\n",
      "Viterbi[1, 6] = 0.0000065 * 0.0000000 = 0.0000000\n",
      "Backpointer[1, 6] = NNP\n",
      "Probability for choosing tag 'DT' at word 'will': 0.0000065\n",
      "\n",
      "Current word: back\n",
      "Viterbi[2, 0] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[2, 0] = MD\n",
      "Probability for choosing tag 'NNP' at word 'back': 0.0000000\n",
      "Viterbi[2, 1] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[2, 1] = MD\n",
      "Probability for choosing tag 'MD' at word 'back': 0.0000000\n",
      "Viterbi[2, 2] = 0.0000000 * 0.0006720 = 0.0000000\n",
      "Backpointer[2, 2] = MD\n",
      "Probability for choosing tag 'VB' at word 'back': 0.0000000\n",
      "Viterbi[2, 3] = 0.0000000 * 0.0003400 = 0.0000000\n",
      "Backpointer[2, 3] = MD\n",
      "Probability for choosing tag 'JJ' at word 'back': 0.0000000\n",
      "Viterbi[2, 4] = 0.0000000 * 0.0002230 = 0.0000000\n",
      "Backpointer[2, 4] = MD\n",
      "Probability for choosing tag 'NN' at word 'back': 0.0000000\n",
      "Viterbi[2, 5] = 0.0000000 * 0.0104460 = 0.0000000\n",
      "Backpointer[2, 5] = MD\n",
      "Probability for choosing tag 'RB' at word 'back': 0.0000000\n",
      "Viterbi[2, 6] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[2, 6] = MD\n",
      "Probability for choosing tag 'DT' at word 'back': 0.0000000\n",
      "\n",
      "Current word: the\n",
      "Viterbi[3, 0] = 0.0000000 * 0.0000480 = 0.0000000\n",
      "Backpointer[3, 0] = RB\n",
      "Probability for choosing tag 'NNP' at word 'the': 0.0000000\n",
      "Viterbi[3, 1] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 1] = RB\n",
      "Probability for choosing tag 'MD' at word 'the': 0.0000000\n",
      "Viterbi[3, 2] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 2] = VB\n",
      "Probability for choosing tag 'VB' at word 'the': 0.0000000\n",
      "Viterbi[3, 3] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 3] = NN\n",
      "Probability for choosing tag 'JJ' at word 'the': 0.0000000\n",
      "Viterbi[3, 4] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 4] = RB\n",
      "Probability for choosing tag 'NN' at word 'the': 0.0000000\n",
      "Viterbi[3, 5] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[3, 5] = RB\n",
      "Probability for choosing tag 'RB' at word 'the': 0.0000000\n",
      "Viterbi[3, 6] = 0.0000000 * 0.5060990 = 0.0000000\n",
      "Backpointer[3, 6] = RB\n",
      "Probability for choosing tag 'DT' at word 'the': 0.0000000\n",
      "\n",
      "Current word: bill\n",
      "Viterbi[4, 0] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 0] = DT\n",
      "Probability for choosing tag 'NNP' at word 'bill': 0.0000000\n",
      "Viterbi[4, 1] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 1] = DT\n",
      "Probability for choosing tag 'MD' at word 'bill': 0.0000000\n",
      "Viterbi[4, 2] = 0.0000000 * 0.0000280 = 0.0000000\n",
      "Backpointer[4, 2] = DT\n",
      "Probability for choosing tag 'VB' at word 'bill': 0.0000000\n",
      "Viterbi[4, 3] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 3] = DT\n",
      "Probability for choosing tag 'JJ' at word 'bill': 0.0000000\n",
      "Viterbi[4, 4] = 0.0000000 * 0.0023370 = 0.0000000\n",
      "Backpointer[4, 4] = DT\n",
      "Probability for choosing tag 'NN' at word 'bill': 0.0000000\n",
      "Viterbi[4, 5] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 5] = DT\n",
      "Probability for choosing tag 'RB' at word 'bill': 0.0000000\n",
      "Viterbi[4, 6] = 0.0000000 * 0.0000000 = 0.0000000\n",
      "Backpointer[4, 6] = DT\n",
      "Probability for choosing tag 'DT' at word 'bill': 0.0000000\n",
      "\n",
      "Most likely sequence of POS tags:\n",
      "['NNP', 'MD', 'RB', 'DT', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    print(f\"\\nCurrent word: {sentence.split()[i]}\")\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob * observation_probs[j, i]\n",
    "        backpointer[i, j] = max_index\n",
    "        print(f\"Viterbi[{i}, {j}] = {max_prob:.7f} * {observation_probs[j, i]:.7f} = {viterbi[i, j]:.7f}\")\n",
    "        print(f\"Backpointer[{i}, {j}] = {tags[max_index]}\")\n",
    "        print(f\"Probability for choosing tag '{tags[j]}' at word '{sentence.split()[i]}': {max_prob:.7f}\")\n",
    "\n",
    "# Step 3: Perform backtracking to find the most likely sequence\n",
    "best_path_prob = np.max(viterbi[-1])\n",
    "best_path_end_tag = np.argmax(viterbi[-1])\n",
    "best_path = [best_path_end_tag]\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    best_path_end_tag = backpointer[i, best_path_end_tag]\n",
    "    best_path.insert(0, best_path_end_tag)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(\"\\nMost likely sequence of POS tags:\")\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum probability for will: 0.0000000800\n",
      "Maximum probability for back: 0.0000000004\n",
      "Maximum probability for the: 0.0000000000\n",
      "Maximum probability for bill: 0.0000000000\n",
      "\n",
      "Most likely sequence of POS tags:\n",
      "['NNP', 'MD', 'VB', 'DT', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "# Define the observation and transition probabilities\n",
    "observation_probs = np.array([\n",
    "    [0.000032, 0, 0, 0.000048, 0],\n",
    "    [0, 0.308431, 0, 0, 0],\n",
    "    [0, 0.000028, 0.000672, 0, 0.000028],\n",
    "    [0, 0, 0.000340, 0, 0],\n",
    "    [0, 0.000200, 0.000223, 0, 0.002337],\n",
    "    [0, 0, 0.010446, 0, 0],\n",
    "    [0, 0, 0, 0.506099, 0]\n",
    "])\n",
    "\n",
    "transition_probs = np.array([\n",
    "    #[0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026],\n",
    "    [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025],\n",
    "    [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041],\n",
    "    [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231],\n",
    "    [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036],\n",
    "    [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068],\n",
    "    [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479],\n",
    "    [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "])\n",
    "\n",
    "# Define the POS tags\n",
    "tags = ['NNP', 'MD', 'VB', 'JJ', 'NN', 'RB', 'DT']\n",
    "\n",
    "# Initialize the Viterbi matrices\n",
    "num_words = len(sentence.split())\n",
    "num_tags = len(tags)\n",
    "viterbi = np.zeros((num_words, num_tags))\n",
    "backpointer = np.zeros((num_words, num_tags), dtype=int)\n",
    "\n",
    "# Step 1: Compute the initial probabilities\n",
    "for j in range(num_tags):\n",
    "    viterbi[0, j] = 1.0 * observation_probs[j, 0]  # Multiply by emission probability of Janet\n",
    "\n",
    "# Step 2: Perform the dynamic programming steps\n",
    "for i in range(1, num_words):\n",
    "    for j in range(num_tags):\n",
    "        max_prob = -1\n",
    "        max_index = -1\n",
    "        for k in range(num_tags):\n",
    "            prob = viterbi[i-1, k] * transition_probs[k, j]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_index = k\n",
    "        viterbi[i, j] = max_prob * observation_probs[j, i]\n",
    "        backpointer[i, j] = max_index\n",
    "    # print(f\"Maximum probability for {sentence.split()[i]}: {max_prob:.7f}\")\n",
    "    print(f\"Maximum probability for {sentence.split()[i]}: {max_prob:.10f}\")\n",
    "\n",
    "# Step 3: Perform backtracking to find the most likely sequence\n",
    "best_path_prob = np.max(viterbi[-1])\n",
    "best_path_end_tag = np.argmax(viterbi[-1])\n",
    "best_path = [best_path_end_tag]\n",
    "for i in range(num_words - 1, 0, -1):\n",
    "    best_path_end_tag = backpointer[i, best_path_end_tag]\n",
    "    best_path.insert(0, best_path_end_tag)\n",
    "\n",
    "# Map the tag indices to actual tags\n",
    "best_path_tags = [tags[tag_index] for tag_index in best_path]\n",
    "\n",
    "# Print the most likely sequence of POS tags\n",
    "print(\"\\nMost likely sequence of POS tags:\")\n",
    "print(best_path_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
