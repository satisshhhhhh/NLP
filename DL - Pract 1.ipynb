{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdad3cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c073dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(x):\n",
    "    if x > 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5970d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input database\n",
    "inputs = np.array([[0,0], [0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41ab6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random weights and bias initialization\n",
    "hidden_weights = np.array([[1,-1], [-1,1]])\n",
    "hidden_bias = np.array([1,1,1,1])\n",
    "output_weights = [2,2]\n",
    "output_bias = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d0ddc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hiddden weights: [[ 1 -1]\n",
      " [-1  1]]\n",
      "Initial hiddden bias: [1 1 1 1]\n",
      "Initial output weights: [2, 2]\n",
      "Initial output biases: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial hiddden weights: \", end=\"\")\n",
    "print(hidden_weights)\n",
    "print(\"Initial hiddden bias: \", end=\"\")\n",
    "print(hidden_bias)\n",
    "print(\"Initial output weights: \", end=\"\")\n",
    "print(output_weights)\n",
    "print(\"Initial output biases: \", end=\"\")\n",
    "print(output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77be1607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input combination  1\n",
      "Hidden layer neuron 1 :  1\n",
      "After threshold  0\n",
      "Hidden layer neuron 2 :  1\n",
      "After threshold  0\n",
      "Input combination  2\n",
      "Hidden layer neuron 1 :  0\n",
      "After threshold  0\n",
      "Hidden layer neuron 2 :  2\n",
      "After threshold  1\n",
      "Input combination  3\n",
      "Hidden layer neuron 1 :  2\n",
      "After threshold  1\n",
      "Hidden layer neuron 2 :  0\n",
      "After threshold  0\n",
      "Input combination  4\n",
      "Hidden layer neuron 1 :  1\n",
      "After threshold  0\n",
      "Hidden layer neuron 2 :  1\n",
      "After threshold  0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inputs)):\n",
    "    print(\"Input combination \",i+1)\n",
    "    hidden_layer1=inputs[i][0]*hidden_weights[0][0]+inputs[i][1]*hidden_weights[0][1]+1\n",
    "    print(\"Hidden layer neuron 1 : \",hidden_layer1)\n",
    "    hidden_layer_activation1=threshold(hidden_layer1)\n",
    "    print(\"After threshold \",hidden_layer_activation1)\n",
    "    hidden_layer2=inputs[i][0]*hidden_weights[1][0]+inputs[i][1]*hidden_weights[1][1]+1\n",
    "    print(\"Hidden layer neuron 2 : \",hidden_layer2)\n",
    "    hidden_layer_activation2=threshold(hidden_layer2)\n",
    "    print(\"After threshold \",hidden_layer_activation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d456c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c354f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea9bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb06f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9063e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26cfff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbc4e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bf2403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b9aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e6f321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d9ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb71ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e4906d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b28611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff1d737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c5a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81804240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a304b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772fe2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183eb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e86603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c74e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161dc137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f50e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4213a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff86df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd075fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efedca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"1_Perceptron_MLP.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1CCjaTOwfw_rfrlEYD2yl03VA3BVpn8vk\n",
    "\n",
    "# Code to implement Perceptron and Multi layer Perceptron and to train them on AND and OR Data sets\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork():\n",
    "  def __init__(self):\n",
    "\n",
    "    np.random.seed(1)\n",
    "    self.weights = 2 *np.random.random((3,1)) - 1\n",
    "\n",
    "  def sigmoid(self,x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "  def sigmoid_derivative(self,x):\n",
    "    return x * (1-x)\n",
    "\n",
    "  def train(self, training_inputs,training_outputs, training_iterations):\n",
    "\n",
    "    for iteration in range(training_iterations):\n",
    "\n",
    "      output = self.nn(training_inputs)\n",
    "\n",
    "      error = training_outputs - output\n",
    "\n",
    "      adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
    "\n",
    "      self.weights += adjustments\n",
    "\n",
    "  def nn(self,inputs):\n",
    "    inputs = inputs.astype(float)\n",
    "    output = self.sigmoid(np.dot(inputs, self.weights))\n",
    "    return output\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "  neural_network = NeuralNetwork()\n",
    "\n",
    "  print(\"Begining With Randomly Generated Weights\")\n",
    "  print(neural_network.weights)\n",
    "\n",
    "  training_inputs = np.array([[0,0,1],\n",
    "                              [1,1,1],\n",
    "                              [1,0,1],\n",
    "                              [0,1,1]])\n",
    "  training_outputs = np.array([[0,1,0,0]]).T\n",
    "\n",
    "  neural_network.train(training_inputs,training_outputs,15000)\n",
    "\n",
    "  print(\"Weights After Training : \")\n",
    "  print(neural_network.weights)\n",
    "  print(\"New Output Data : \")\n",
    "  print(neural_network.nn(np.array([1,1,1])))\n",
    "\n",
    "\"\"\"#For AND Data Set\"\"\"\n",
    "\n",
    "nn = neural_network\n",
    "print(\"Random weights init\")\n",
    "print(nn.weights)\n",
    "train_inp = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "train_out = np.array([[0,0,0,1]]).T\n",
    "nn.train(train_inp, train_out, 500)\n",
    "print(\"Final weights\")\n",
    "print(nn.weights)\n",
    "print(nn.nn(np.array([1,1,1])))\n",
    "\n",
    "\"\"\"#For OR Data Set\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "nn = neural_network\n",
    "print(\"Random weights init\")\n",
    "print(nn.weights)\n",
    "train_inp = np.array([[0,0,1],[1,1,1],[1,0,1],[0,1,1]])\n",
    "train_out = np.array([[0,1,1,1]]).T\n",
    "nn.train(train_inp, train_out, 40)\n",
    "print(\"Final weights\")\n",
    "print(nn.weights)\n",
    "\n",
    "print(nn.nn(np.array([1,1,1])))\n",
    "\n",
    "\"\"\"# MLP\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np #np.random. seed()\n",
    "\n",
    "def sigmoid (x): return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x): return x * (1 - x)\n",
    "\n",
    "def threshold (x):\n",
    "  if x>1:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "#Input datasets\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "epochs = 1\n",
    "lr = 0.1\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
    "\n",
    "#Random weights and bias initialization\n",
    "#hidden_weights = np.random.uniform( size=(inputLayerNeurons, hiddenLayerNeurons))\n",
    "hidden_weights=[[1,-1],[1,-1]]\n",
    "#hidden_bias =np.random.uniform(size=(1, hiddenLayerNeurons))\n",
    "hidden_bias=[1,1]\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons, outputLayerNeurons) )\n",
    "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
    "\n",
    "print(\"Initial hidden weights: \", end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \", end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \", end='')\n",
    "print(output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(output_bias)\n",
    "\n",
    "#Training algorithm\n",
    "for _ in range(epochs):\n",
    "    hidden_layer_activation = np.dot(inputs, hidden_weights)\n",
    "    hidden_layer_activation += hidden_bias\n",
    "    hidden_layer_output = threshold(hidden_layer_activation)\n",
    "    output_layer_activation = np.dot (hidden_layer_output, output_weights)\n",
    "    output_layer_activation += output_bias\n",
    "    predicted_output = threshold(output_layer_activation)\n",
    "\n",
    "    #error = expected_output - predicted_output\n",
    "    #d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "\n",
    "    #error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "    #d_hidden_layer =  error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "    output_bias += np.sum(d_predicted_output, axis=0, keepdims=True) * lr\n",
    "\n",
    "    #hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "    #hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * lr\n",
    "\n",
    "print(\"Initial hidden weights: \", end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \", end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \", end='')\n",
    "print(output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(output_bias)\n",
    "\n",
    "print(predicted_output)\n",
    "\n",
    "import numpy as np #np.random. seed()\n",
    "\n",
    "\n",
    "\n",
    "def threshold (x):\n",
    "  if x>1:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "#Input datasets\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Random weights and bias initialization\n",
    "hidden_weights = np.array([[1,-1],[-1,1]])\n",
    "hidden_bias =np.array([1,1,1,1])\n",
    "output_weights = [2,2]\n",
    "output_bias = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Initial hidden weights: \", end='')\n",
    "print(hidden_weights)\n",
    "print(\"Initial hidden biases: \", end='')\n",
    "print(hidden_bias)\n",
    "print(\"Initial output weights: \", end='')\n",
    "print(output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(output_bias)\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "  print(\"Input combination \",i+1)\n",
    "  hidden_layer1=inputs[i][0]*hidden_weights[0][0]+inputs[i][1]*hidden_weights[0][1]+1\n",
    "  print(\"Hidden layer neuron 1 : \",hidden_layer1)\n",
    "  hidden_layer_activation1=threshold(hidden_layer1)\n",
    "  print(\"After threshold \",hidden_layer_activation1)\n",
    "  hidden_layer2=inputs[i][0]*hidden_weights[1][0]+inputs[i][1]*hidden_weights[1][1]+1\n",
    "  print(\"Hidden layer neuron 2 : \",hidden_layer2)\n",
    "  hidden_layer_activation2=threshold(hidden_layer2)\n",
    "  print(\"After threshold \",hidden_layer_activation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbb6adfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Hidden Layer Output:\n",
      "Input: [0. 0.] Output: 1.0\n",
      "Input: [0. 1.] Output: 0.0\n",
      "Input: [1. 0.] Output: 2.0\n",
      "Input: [1. 1.] Output: 1.0\n",
      "\n",
      "Second Hidden Layer Output:\n",
      "Input: [0. 0.] Output: 0.0\n",
      "Input: [0. 1.] Output: 2.0\n",
      "Input: [1. 0.] Output: 0.0\n",
      "Input: [1. 1.] Output: 1.0\n",
      "\n",
      "Final Output:\n",
      "Input: [0. 0.] Output: 0\n",
      "Input: [0. 1.] Output: 1\n",
      "Input: [1. 0.] Output: 0\n",
      "Input: [1. 1.] Output: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define inputs\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "\n",
    "# Define weights and biases for the first hidden layer\n",
    "w1 = 1\n",
    "w2 = -1\n",
    "b1 = 1\n",
    "\n",
    "# Calculate the first hidden layer output (h1)\n",
    "h1 = np.maximum(X[:, 0] * w1 + X[:, 1] * w2 + b1, 0)\n",
    "\n",
    "# Print the first hidden layer output\n",
    "print(\"First Hidden Layer Output:\")\n",
    "for i in range(len(X)):\n",
    "    print(\"Input:\", X[i], \"Output:\", h1[i])\n",
    "\n",
    "# Define weights and biases for the second hidden layer\n",
    "w3 = -1\n",
    "w4 = 1\n",
    "b2 = 1\n",
    "\n",
    "# Calculate the second hidden layer output (h2)\n",
    "h2 = np.maximum(h1 * w3 + X[:, 1] * w4 + b2, 0)\n",
    "\n",
    "# Print the second hidden layer output\n",
    "print(\"\\nSecond Hidden Layer Output:\")\n",
    "for i in range(len(X)):\n",
    "    print(\"Input:\", X[i], \"Output:\", h2[i])\n",
    "\n",
    "# Define expected output\n",
    "expected_output = np.array([0, 1, 1, 0], dtype=np.float32)\n",
    "\n",
    "# Calculate the final output using an activation function\n",
    "output = np.where(h2 >= 0.5, 1, 0)\n",
    "\n",
    "# Print the final output\n",
    "print(\"\\nFinal Output:\")\n",
    "for i in range(len(X)):\n",
    "    print(\"Input:\", X[i], \"Output:\", output[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c870d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Hidden Layer Output:\n",
      "Input: [0. 0.] Output: 1.0\n",
      "Input: [0. 1.] Output: 0.0\n",
      "Input: [1. 0.] Output: 2.0\n",
      "Input: [1. 1.] Output: 1.0\n",
      "\n",
      "Second Hidden Layer Output:\n",
      "Input: [0. 0.] Output: 1.0\n",
      "Input: [0. 1.] Output: 2.0\n",
      "Input: [1. 0.] Output: 0.0\n",
      "Input: [1. 1.] Output: 1.0\n",
      "\n",
      "Final Output:\n",
      "Input: [0. 0.] Output: 1\n",
      "Input: [0. 1.] Output: 1\n",
      "Input: [1. 0.] Output: 1\n",
      "Input: [1. 1.] Output: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define inputs\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "\n",
    "# Define weights and biases for the first hidden layer\n",
    "w1 = 1\n",
    "w2 = -1\n",
    "b1 = 1\n",
    "\n",
    "# Calculate the first hidden layer output (h1)\n",
    "h1 = np.maximum(X[:, 0] * w1 + X[:, 1] * w2 + b1, 0)\n",
    "\n",
    "# Print the first hidden layer output\n",
    "print(\"First Hidden Layer Output:\")\n",
    "for i in range(len(X)):\n",
    "    print(\"Input:\", X[i], \"Output:\", h1[i])\n",
    "\n",
    "# Define weights and biases for the second hidden layer\n",
    "w3 = -1\n",
    "w4 = 1\n",
    "b2 = 1\n",
    "\n",
    "# Calculate the second hidden layer output (h2)\n",
    "h2 = np.maximum(X[:, 0] * w3 + X[:, 1] * w4 + b2, 0)\n",
    "\n",
    "# Print the second hidden layer output\n",
    "print(\"\\nSecond Hidden Layer Output:\")\n",
    "for i in range(len(X)):\n",
    "    print(\"Input:\", X[i], \"Output:\", h2[i])\n",
    "\n",
    "# Define weights and bias for the output layer\n",
    "w5 = 2\n",
    "w6 = 2\n",
    "b3 = -3\n",
    "\n",
    "# Calculate the output (y)\n",
    "output = np.where(h1 * w5 + h2 * w6 + b3 >= 0, 1, 0)\n",
    "\n",
    "# Print the final output\n",
    "print(\"\\nFinal Output:\")\n",
    "for i in range(len(X)):\n",
    "    print(\"Input:\", X[i], \"Output:\", output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf891505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer H1: 1\n",
      "Hidden Layer H2: 1\n",
      "Output (y): 1\n"
     ]
    }
   ],
   "source": [
    "def threshold_activation(value, threshold):\n",
    "    if value >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Define the weights and biases\n",
    "weights_x1 = [1, -1]\n",
    "weights_x2 = [-1, 1]\n",
    "bias_h1 = 1\n",
    "bias_h2 = 1\n",
    "weights_h1 = 2\n",
    "weights_h2 = 2\n",
    "bias_h3 = 1\n",
    "threshold = 5  # Set the threshold value\n",
    "\n",
    "# Calculate the values of the hidden layers\n",
    "x1 = 1\n",
    "x2 = -1\n",
    "\n",
    "h1 = (weights_h1 * x1) + (weights_h1 * x2) + bias_h1\n",
    "h2 = (weights_h2 * x1) + (weights_h2 * x2) + bias_h2\n",
    "\n",
    "# Calculate the value of the output layer (H3)\n",
    "h3 = (weights_h1 * h1) + (weights_h2 * h2) + bias_h3\n",
    "\n",
    "# Apply the threshold activation function to get the output (y)\n",
    "y = threshold_activation(h3, threshold)\n",
    "\n",
    "# Print the results\n",
    "print(\"Hidden Layer H1:\", h1)\n",
    "print(\"Hidden Layer H2:\", h2)\n",
    "print(\"Output (y):\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c681654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96321d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hidden weights: [0.02191079 0.29965507] [0.39158991 0.79870589]\n",
      "Initial hidden biases: [0.78344774 0.35331588]\n",
      "Initial output weights: [0.5193197] [0.65621802]\n",
      "Initial output biases: [0.06984377]\n",
      "Final hidden weights: [3.63673152 5.83000514] [3.65011906 5.90258688]\n",
      "Final hidden bias: [-5.57281757 -2.43406782]\n",
      "Final output weights: [-8.11313292] [7.45344518]\n",
      "Final output bias: [-3.34072815]\n",
      "\n",
      "Output from neural network after 10,000 epochs: [0.05893914] [0.94544413] [0.94521777] [0.05938035]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "#np.random.seed(0)\n",
    "\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "#Input datasets\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "epochs = 10000\n",
    "lr = 0.1\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
    "\n",
    "#Random weights and bias initialization\n",
    "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
    "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
    "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
    "\n",
    "print(\"Initial hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "\n",
    "#Training algorithm\n",
    "for _ in range(epochs):\n",
    "\t#Forward Propagation\n",
    "\thidden_layer_activation = np.dot(inputs,hidden_weights)\n",
    "\thidden_layer_activation += hidden_bias\n",
    "\thidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "\toutput_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
    "\toutput_layer_activation += output_bias\n",
    "\tpredicted_output = sigmoid(output_layer_activation)\n",
    "\n",
    "\t#Backpropagation\n",
    "\terror = expected_output - predicted_output\n",
    "\td_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "\t\n",
    "\terror_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "\td_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "\t#Updating Weights and Biases\n",
    "\toutput_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "\toutput_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
    "\thidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "\thidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
    "\n",
    "print(\"Final hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Final hidden bias: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Final output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Final output bias: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
    "print(*predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2822b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1b045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd97b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f48a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
