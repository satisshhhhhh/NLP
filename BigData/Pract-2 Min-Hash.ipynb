{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c67831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1 words: ['hey', 'how', 'are', 'you', 'doing']\n",
      "File 2 words: ['an', 'understanding', 'man', 'is', 'smart']\n",
      "File 3 words: ['Hard', 'times', 'always', 'lead', 'to', 'something', 'great']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read the input files\n",
    "file1_words = []\n",
    "file2_words = []\n",
    "file3_words = []\n",
    "\n",
    "# Function to read words from a file\n",
    "def read_words_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        words = file.read().split()\n",
    "    return words\n",
    "\n",
    "# Replace 'file1.txt', 'file2.txt', and 'file3.txt' with actual file paths\n",
    "file1_words = read_words_from_file('file1.txt')\n",
    "file2_words = read_words_from_file('file2.txt')\n",
    "file3_words = read_words_from_file('file3.txt')\n",
    "\n",
    "print(\"File 1 words:\", file1_words)\n",
    "print(\"File 2 words:\", file2_words)\n",
    "print(\"File 3 words:\", file3_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f78b0021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1 singles: ['a', 'd', 'e', 'g', 'h', 'i', 'n', 'o', 'r', 'u', 'w', 'y']\n",
      "File 2 singles: ['a', 'd', 'e', 'g', 'i', 'm', 'n', 'r', 's', 't', 'u']\n",
      "File 3 singles: ['a', 'd', 'e', 'g', 'h', 'i', 'l', 'm', 'n', 'o', 'r', 's', 't', 'w', 'y']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate singles for words and letters\n",
    "def generate_singles(words):\n",
    "    singles = set()\n",
    "    for word in words:\n",
    "        singles.update(word.lower())  # Considering case-insensitive singles\n",
    "    return sorted(list(singles))\n",
    "\n",
    "file1_singles = generate_singles(file1_words)\n",
    "file2_singles = generate_singles(file2_words)\n",
    "file3_singles = generate_singles(file3_words)\n",
    "\n",
    "print(\"File 1 singles:\", file1_singles)\n",
    "print(\"File 2 singles:\", file2_singles)\n",
    "print(\"File 3 singles:\", file3_singles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90caecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incidence matrix:\n",
      "[1, 0, 0]\n",
      "[1, 0, 0]\n",
      "[1, 0, 0]\n",
      "[1, 0, 0]\n",
      "[0, 0, 1]\n",
      "[0, 1, 0]\n",
      "[0, 1, 0]\n",
      "[0, 1, 0]\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "[0, 1, 0]\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "[1, 0, 0]\n",
      "[0, 1, 0]\n",
      "[0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create an incidence matrix\n",
    "unique_words = list(set(file1_words + file2_words + file3_words))\n",
    "incidence_matrix = []\n",
    "\n",
    "for word in unique_words:\n",
    "    row = [1 if word in file1_words else 0,\n",
    "           1 if word in file2_words else 0,\n",
    "           1 if word in file3_words else 0]\n",
    "    incidence_matrix.append(row)\n",
    "\n",
    "print(\"Incidence matrix:\")\n",
    "for row in incidence_matrix:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ba286f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-hash values:\n",
      "Hash Function 1: [1, 1, 1, 1, 5, 3, 3, 3, 5, 5, 5, 3, 5, 5, 1, 3, 5]\n",
      "Hash Function 2: [2, 2, 2, 2, 1, 7, 7, 7, 1, 1, 1, 7, 1, 1, 2, 7, 1]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Min-hashing on incidence matrix with 2 hash functions\n",
    "num_hashes = 2  # Number of hash functions\n",
    "\n",
    "def hash_function_1(x):\n",
    "    return (2 * x + 1) % 11\n",
    "\n",
    "def hash_function_2(x):\n",
    "    return (5 * x + 2) % 11\n",
    "\n",
    "def generate_min_hash(incidence_matrix, num_hashes):\n",
    "    min_hash_values = []\n",
    "    num_docs = len(incidence_matrix[0])\n",
    "\n",
    "    for i in range(num_hashes):\n",
    "        min_hash = []\n",
    "        for word_row in incidence_matrix:\n",
    "            hash_val = float('inf')\n",
    "            for doc_idx in range(num_docs):\n",
    "                if word_row[doc_idx] == 1:\n",
    "                    if i == 0:\n",
    "                        hash_val = min(hash_val, hash_function_1(doc_idx))\n",
    "                    elif i == 1:\n",
    "                        hash_val = min(hash_val, hash_function_2(doc_idx))\n",
    "            min_hash.append(hash_val)\n",
    "        min_hash_values.append(min_hash)\n",
    "\n",
    "    return min_hash_values\n",
    "\n",
    "min_hash_values = generate_min_hash(incidence_matrix, num_hashes)\n",
    "\n",
    "print(\"Min-hash values:\")\n",
    "for i, min_hash in enumerate(min_hash_values):\n",
    "    print(f\"Hash Function {i+1}: {min_hash}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261033b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcefd16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incidence Matrix:\n",
      "+----------------------+--------------+--------------+--------------+\n",
      "| Shingle              |   Document 1 |   Document 2 |   Document 3 |\n",
      "+======================+==============+==============+==============+\n",
      "| are you doing        |            1 |            0 |            0 |\n",
      "+----------------------+--------------+--------------+--------------+\n",
      "| how are you          |            1 |            0 |            0 |\n",
      "+----------------------+--------------+--------------+--------------+\n",
      "| hey how are          |            1 |            0 |            0 |\n",
      "+----------------------+--------------+--------------+--------------+\n",
      "| man is smart         |            0 |            1 |            0 |\n",
      "+----------------------+--------------+--------------+--------------+\n",
      "| an understanding man |            0 |            1 |            0 |\n",
      "+----------------------+--------------+--------------+--------------+\n",
      "| understanding man is |            0 |            1 |            0 |\n",
      "+----------------------+--------------+--------------+--------------+\n",
      "| always lead to       |            0 |            0 |            1 |\n",
      "+----------------------+--------------+--------------+--------------+\n",
      "| times always lead    |            0 |            0 |            1 |\n",
      "+----------------------+--------------+--------------+--------------+\n",
      "| hard times always    |            0 |            0 |            1 |\n",
      "+----------------------+--------------+--------------+--------------+\n",
      "| lead to something    |            0 |            0 |            1 |\n",
      "+----------------------+--------------+--------------+--------------+\n",
      "| to something great   |            0 |            0 |            1 |\n",
      "+----------------------+--------------+--------------+--------------+\n",
      "\n",
      "Minhash Signature Matrix:\n",
      "+------------+----------+----------+\n",
      "| Shingle    |   Hash 1 |   Hash 2 |\n",
      "+============+==========+==========+\n",
      "| Shingle 1  |        3 |        3 |\n",
      "+------------+----------+----------+\n",
      "| Shingle 2  |        3 |        3 |\n",
      "+------------+----------+----------+\n",
      "| Shingle 3  |        3 |        3 |\n",
      "+------------+----------+----------+\n",
      "| Shingle 4  |        5 |        5 |\n",
      "+------------+----------+----------+\n",
      "| Shingle 5  |        5 |        5 |\n",
      "+------------+----------+----------+\n",
      "| Shingle 6  |        5 |        5 |\n",
      "+------------+----------+----------+\n",
      "| Shingle 7  |        7 |        7 |\n",
      "+------------+----------+----------+\n",
      "| Shingle 8  |        7 |        7 |\n",
      "+------------+----------+----------+\n",
      "| Shingle 9  |        7 |        7 |\n",
      "+------------+----------+----------+\n",
      "| Shingle 10 |        7 |        7 |\n",
      "+------------+----------+----------+\n",
      "| Shingle 11 |        7 |        7 |\n",
      "+------------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Function to generate K-shingles from a document\n",
    "def generate_k_shingles(document, k):\n",
    "    words = re.findall(r'\\w+', document.lower())\n",
    "    shingles = set()\n",
    "    for i in range(len(words) - k + 1):\n",
    "        shingle = ' '.join(words[i:i+k])\n",
    "        shingles.add(shingle)\n",
    "    return shingles\n",
    "\n",
    "# Function to create K-shingles incidence matrix\n",
    "def create_incidence_matrix(documents, k):\n",
    "    incidence_matrix = {}\n",
    "    for i, doc in enumerate(documents):\n",
    "        shingles = generate_k_shingles(doc, k)\n",
    "        for shingle in shingles:\n",
    "            if shingle in incidence_matrix:\n",
    "                incidence_matrix[shingle][i] = 1\n",
    "            else:\n",
    "                incidence_matrix[shingle] = [0] * len(documents)\n",
    "                incidence_matrix[shingle][i] = 1\n",
    "    return incidence_matrix\n",
    "\n",
    "# Function to apply Minhash functions and get signature\n",
    "def get_minhash_signature(incidence_matrix, num_hashes):\n",
    "    signature_matrix = []\n",
    "    for shingle, row in incidence_matrix.items():\n",
    "        signature = []\n",
    "        for i in range(num_hashes):\n",
    "            minhash_value = float('inf')\n",
    "            for j, val in enumerate(row):\n",
    "                if val == 1:\n",
    "                    hash_value = (2 * j + 3) % 11  # Apply h1 = (2x + 3) mod 11\n",
    "                    minhash_value = min(minhash_value, hash_value)\n",
    "            signature.append(minhash_value)\n",
    "        signature_matrix.append(signature)\n",
    "    return signature_matrix\n",
    "\n",
    "# Example usage\n",
    "file1 = \"file1.txt\"\n",
    "file2 = \"file2.txt\"\n",
    "file3 = \"file3.txt\"\n",
    "\n",
    "documents = []\n",
    "\n",
    "# Read the contents of the files\n",
    "with open(file1, \"r\") as f:\n",
    "    document1 = f.read()\n",
    "    documents.append(document1)\n",
    "\n",
    "with open(file2, \"r\") as f:\n",
    "    document2 = f.read()\n",
    "    documents.append(document2)\n",
    "\n",
    "with open(file3, \"r\") as f:\n",
    "    document3 = f.read()\n",
    "    documents.append(document3)\n",
    "\n",
    "k = 3\n",
    "\n",
    "incidence_matrix = create_incidence_matrix(documents, k)\n",
    "\n",
    "# Convert incidence matrix to a table format\n",
    "table = []\n",
    "header = [\"Shingle\"] + [f\"Document {i+1}\" for i in range(len(documents))]\n",
    "for shingle, row in incidence_matrix.items():\n",
    "    table.append([shingle] + row)\n",
    "\n",
    "# Print the incidence matrix in table format\n",
    "print(\"Incidence Matrix:\")\n",
    "print(tabulate(table, headers=header, tablefmt=\"grid\"))\n",
    "\n",
    "num_hashes = 2\n",
    "signature_matrix = get_minhash_signature(incidence_matrix, num_hashes)\n",
    "\n",
    "# Convert signature matrix to a table format\n",
    "table = []\n",
    "header = [\"Shingle\"] + [f\"Hash {i+1}\" for i in range(num_hashes)]\n",
    "for i, signature in enumerate(signature_matrix):\n",
    "    table.append([f\"Shingle {i+1}\"] + signature)\n",
    "\n",
    "# Print the Minhash signature matrix in table format\n",
    "print(\"\\nMinhash Signature Matrix:\")\n",
    "print(tabulate(table, headers=header, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5510977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "824ca26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incidence Matrix:\n",
      "Word             Document 1    Document 2    Document 3\n",
      "-------------  ------------  ------------  ------------\n",
      "Hard                      0             0             1\n",
      "always                    0             0             1\n",
      "an                        0             1             0\n",
      "are                       1             0             0\n",
      "doing                     1             0             0\n",
      "great                     0             0             1\n",
      "hey                       1             0             0\n",
      "how                       1             0             0\n",
      "is                        0             1             0\n",
      "lead                      0             0             1\n",
      "man                       0             1             0\n",
      "smart                     0             1             0\n",
      "something                 0             0             1\n",
      "times                     0             0             1\n",
      "to                        0             0             1\n",
      "understanding             0             1             0\n",
      "you                       1             0             0\n",
      "\n",
      "Min-Hash Signatures:\n",
      "Signature for hash function 1: [0.0, 1.0, 0.0]\n",
      "Signature for hash function 2: [0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define the hash functions\n",
    "def hash_function_1(x):\n",
    "    return (2 * x + 1) % 11\n",
    "\n",
    "def hash_function_2(x):\n",
    "    return (5 * x + 2) % 11\n",
    "\n",
    "# Function to generate shingles for words and letters\n",
    "def generate_shingles(text):\n",
    "    words = text.split()\n",
    "    letters = \"\".join(text.split())\n",
    "    return set(words), set(letters)\n",
    "\n",
    "# Function to create the incidence matrix for unique words in the documents\n",
    "def create_incidence_matrix(documents):\n",
    "    unique_words = sorted(set(word for doc in documents for word in doc))\n",
    "    incidence_matrix = np.zeros((len(unique_words), len(documents)), dtype=int)\n",
    "\n",
    "    for j, doc in enumerate(documents):\n",
    "        for i, word in enumerate(unique_words):\n",
    "            incidence_matrix[i, j] = int(word in doc)\n",
    "\n",
    "    return unique_words, incidence_matrix\n",
    "\n",
    "# Function to perform min-hashing on the incidence matrix\n",
    "def min_hashing(incidence_matrix, hash_functions):\n",
    "    num_hashes = len(hash_functions)\n",
    "    num_docs = incidence_matrix.shape[1]\n",
    "    min_hash_signatures = np.full((num_hashes, num_docs), np.inf)\n",
    "\n",
    "    for i in range(incidence_matrix.shape[0]):\n",
    "        for j in range(num_docs):\n",
    "            if incidence_matrix[i, j] == 1:\n",
    "                for k, hash_func in enumerate(hash_functions):\n",
    "                    hash_value = hash_func(i)\n",
    "                    min_hash_signatures[k, j] = min(min_hash_signatures[k, j], hash_value)\n",
    "\n",
    "    return min_hash_signatures\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Read three input files, each containing five words\n",
    "    with open(\"file1.txt\", \"r\") as file:\n",
    "        input_file1 = file.read().strip()\n",
    "\n",
    "    with open(\"file2.txt\", \"r\") as file:\n",
    "        input_file2 = file.read().strip()\n",
    "\n",
    "    with open(\"file3.txt\", \"r\") as file:\n",
    "        input_file3 = file.read().strip()\n",
    "\n",
    "    # Generate shingles for words and letters\n",
    "    shingles1_words, shingles1_letters = generate_shingles(input_file1)\n",
    "    shingles2_words, shingles2_letters = generate_shingles(input_file2)\n",
    "    shingles3_words, shingles3_letters = generate_shingles(input_file3)\n",
    "\n",
    "    # Create the incidence matrix for unique words in the documents\n",
    "    unique_words, incidence_matrix = create_incidence_matrix(\n",
    "        [shingles1_words, shingles2_words, shingles3_words]\n",
    "    )\n",
    "\n",
    "    # Perform min-hashing on the incidence matrix\n",
    "    hash_functions = [hash_function_1, hash_function_2]\n",
    "    min_hash_signatures = min_hashing(incidence_matrix, hash_functions)\n",
    "\n",
    "    # Print the incidence matrix using tabulate\n",
    "    table_data = [[\"Word\"] + [f\"Document {i+1}\" for i in range(3)]]\n",
    "    for i, word in enumerate(unique_words):\n",
    "        row = [word] + list(incidence_matrix[i])\n",
    "        table_data.append(row)\n",
    "\n",
    "    print(\"Incidence Matrix:\")\n",
    "    print(tabulate(table_data, headers=\"firstrow\"))\n",
    "\n",
    "    # Print the min-hash signatures\n",
    "    print(\"\\nMin-Hash Signatures:\")\n",
    "    for i, signature in enumerate(min_hash_signatures):\n",
    "        print(f\"Signature for hash function {i+1}: {list(signature)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73239b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee04641d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91441810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e56ce3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18ed5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f26ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
